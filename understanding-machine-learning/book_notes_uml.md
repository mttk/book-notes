Currently covered

- Chapter 2
- Chapter 3

### Chapter 2: A gentle start

*Terminology:*

- Domain set (instance space): $\mathcal{X}$, all the objects (instances) we may wish to label. Represented as a vector of features.

- Label set: $\mathcal{Y}$, set of all possible labels, generated by some unknown _true_ labelling function $f$

- Training data $(x,y) \in D, \quad |D| = m$

#### Empirical risk minimization

The _true error_ is defined over the data generating probability distribution $\mathcal{D}$ and labeling function $f$

$$ L_{\mathcal{D}, f} (h) \stackrel{def}{=} \mathcal{P}_ {x\sim \mathcal{D}} [h(x) \neq f(x)] \stackrel{def}{=} \mathcal{D} ( \{ x : h(x) \neq f(x)\}) $$


The _training error_ is defined over the training set (sample) $S$

$$L_S(h) \stackrel{def}{=} \frac{|\{i \in [m] : h(x_i) \neq y_i \}|}{m}$$

**Overfitting**: a trivial classifier that achieves zero training error simply copies labels from examples in the training set, and outputs a random label if the input vector is not from the training set.

A **Hypothesis class** is a set of predictors (family of models) $\mathcal{H}$. Each $h\in \mathcal{H}$ is a function mapping $\mathcal{X}$ to $\mathcal{Y}$.

Formally, the predictor chosen by the ERM rule is the one that minimizes the training error.

\begin{equation}
ERM_{\mathcal{H}} (S) \in \arg\min_{h\in \mathcal{H}} L_S (h)
\label{eq:erm}
\end{equation}

The choice to restrict the hypothesis space is called an _inductive bias_. The choice of a family of predictors should be based on some prior knowledge about the problem. Ideally, we would want guarantees that the chosen family will not overfit.

**DEFINITION 2.1** (The realizability assumption): There exists $h^* \in \mathcal{H}$ s.t. $L_{(\mathcal{D}, f)} (h^* ) = 0$

Note: this definition holds for any $S$ -- $S$ can be any random sample from the true data distribution $D$ labelled by $f$. 

**IID assumption** All samples are _independently_ and _identically_ distributed according to $\mathcal{D}$: $S\sim \mathcal{D}^m$.

Two new parameters are introduced, the _confidence_ of the distribution sample and _accuracy_ of the classifier.

- **Confidence**: parameter $\delta$ denotes the probability of getting a **nonrepresentative** sample of the true distribution. Thus, we call $(1 - \delta)$ the _confidence parameter_

- **Accuracy**: the accuracy parameter $\epsilon$ determines what we consider as failure of the classifier. If $L_{(\mathcal{D}, f)} (h_s) > \epsilon$ we consider this a failure of the learner, while $L_{(\mathcal{D}, f)} (h_s) \le \epsilon$ we consider the algorithm an _approximately correct_ predictor.

With these parameters, we can formally express the _probability_ to sample an $m-$tuple of instances that will lead to failure of teh learner. We define the _bad_ hypotheses as the subset of the hypothesis space which has error greater than $\epsilon$ on the _true_ distribution.

$$
\mathcal{H}_ b = \{ h \in \mathcal{H}: L_{(D,f)} (h) > \epsilon \}
$$

Also, we define the _miseleading_ samples as the data samples which allow a hypothesis from the set of _bad_ hypotheses to minimize the training error (obtain error of 0).

\begin{equation}
M = \{S_x : \exists h \in \mathcal{H}_ B s.t. L_S(h) = 0 \}
\label{eq:badsamples}
\end{equation}

We want to upper bound the number of training samples which produce _bad_ hypotheses (which obtain error lager then $\epsilon$) as the minimizers of the _training_ error.

$$
\mathcal{D}^m (\{ S_x : L_{(\mathcal{D}, f)} (h_S) > \epsilon\})
$$

We can rewrite (\ref{eq:badsamples}) as

$$
M = \bigcup_{h\in \mathcal{H}_ B} \{S_x : L_s(h) = 0\}
$$

the number of failures is bounded by the number of misleading samples (the _less than_ comes from (\ref{eq:erm}) due to the ERM being one out of multiple possible minimizers)

\begin{equation}
\mathcal{D}^m (\{ S_x : L_{(\mathcal{D}, f)} (h_S) > \epsilon\}) \leq \mathcal{D}^m (M) = \mathcal{D}^m (\cup_{h\in \mathcal{H}_ B} \{S_x : L_s(h) = 0\})
\label{eq:failures}
\end{equation}

---------

**Union bound**: for two sets $A$, $B$ and a distribution $\mathcal{D}$, the union bound states that the size of the union of two sets is at most the sum of the sizes of both set (holds with equality when both sets are disjoint): 

$$
\mathcal{D} (A \cup B) \le \mathcal{D} (A) + \mathcal{D}(B)
$$

---------

By union bounding the RHS of (\ref{eq:failures}), we obtain

$$
\mathcal{D}^m (\{ S_x : L_{(\mathcal{D}, f)} (h_S) > \epsilon\}) \leq \sum_{h\in \mathcal{H}_ B} \mathcal{D}^m (\{S_x : L_s(h) = 0\})
$$

TODO: annotate remaining math steps to corollary

**COROLLARY 2.3** $\mathcal{H}$ is a finite hypothesis class. Let $\delta \in (0, 1)$, $\epsilon > 0$ and $m$ is an integer satisfying

$$
m \ge \frac{log(|\mathcal{H}| / \delta)}{\epsilon}
$$

Then, for **any** labeling function $f$ and **any** distribution $\mathcal{D}$ for which the realizability assumption holds, with probability of _at least_ $1 - \delta$ over the choice of an i.i.d. sample $S$ of size $m$, for **every** ERM hypothesis $h_S$, the following holds:

$$
L_{(D, f)} (h_S) \le \epsilon
$$ 

For a sufficiently large $m$, the $ERM_H$ rule over a finite hypothessi class will be _probably_ ($1 - \delta$) _approximately_ (up to error $\epsilon$) correct (PAC).

### Chapter 3: A formal learning model

#### PAC Learning

**DEFINITION 3.1** (PAC Learnability) A hypothesis class $\mathcal{H}$ is PAC learnable if tere exists a function $m_{\mathcal{H}} : (0, 1)^2 \to \mathbb{N}$ and a learning algorithm with the following property: For every $\epsilon, \delta \in (0, 1)$, for every distribution $\mathcal{D}$ over $\mathcal{X}$ and for every labeling function $f: \mathcal{X} \to \{0, 1\}$, if the realizable assumption holds w.r.t $\mathcal{H}, \mathcal{D}, f$, then when rnning the learning algorithm on $m \ge m_{\mathcal{H}}(\epsilon, \delta)$ i.i.d. examples generated by $\mathcal{D}$ and labeled by $f$, the algorithm returns a hypothesis $h$ s.t. with probability $1-\delta$ over the choice of samples, $L_{(\mathcal{D}, f)}(h) \le \epsilon$.

Approximations in PAC Learnability: $\epsilon$ defines the distance we allow from the optimal classifier, while $\delta$ indicates how likely the classifier is to meet that accuracy requirement (based on a sample from $\mathcal{D}$).

**Sample complexity** is the _minimal$^*$_ number of examples formulated as a function of accuracy and confidence required to guarantee a PAC solution. $m_H: (0, 1)^2 \to \mathbb{N}$ or, $m_H: (\epsilon, \delta) \to \mathbb{N}$. 

**COROLLARY 3.2** Every finite hypothesis class is PAC learnable with sample complexity

$$
m_H (\epsilon, \delta) \le \Big\lceil\frac{log(|\mathcal{H}| / \delta)}{\epsilon}\Big\rceil
$$

**Relaxations**: Two relaxations with respect to our original problem are necessary for real-world problems:

- Removing the realizability assumption (_agnostic_ PAC)

- Learning problems beyond binary classification 

**Agnostic PAC Learning**: practically, it is not realistic that there will exist a classifier which perfectly approximates the labeling function over the whole data distribution. In place of the absolute labelling function $f$, we introduce the conditional probability $D((x,y)\|x)$ indicating the probability of an input sample $x$ to have the class label $y$.

Essentially, the constraint that there exists a $h^* \in \mathcal{H}$ s.t. $\mathcal{P}_ {x\sim D} [h^* (x) = f(x)] = 1$ _(realizability assumption)_ is waived.

**Revising the empirical and true error**

$$
L_D(h) \stackrel{def}{=} \underset{(x,y)\sim \mathcal{D}}{\mathbb{P}} [h(x) \neq y] \stackrel{def}{=} \mathcal{D} (\{ (x,y) : h(x) \neq y\})
$$

Essentially, $f(x)$ is replaced by $y$, signifying that we now randomly draw _labeled points_.

The definition of empirical risk remains the same as before. Note: $L_S(h) = L_{D \text{uniform over} S} (h)$

**The Bayes optimal predictor**:

Given any probability distribution $\mathcal{D}$ over $\mathcal{X} \times \{0, 1\}$, the best label predicting function will be:

$$
f_{\mathcal{D}} (x) =
\begin{cases}
1, & \text{if } \mathcal{P}[y=1 | x] \ge 1/2 \\
0, & \text{otherwise}
\end{cases}
$$

Read: assign class label $1$ to samples that have probability of having label $1$ larger than $0.5$, and $0$ otherwise.
However, we do not know $\mathcal{D}$ and we cannot use this optimal predictor, however it can serve as a lower bound on the error of our predictor.

**DEFINITION 3.3** (Agnostic PAC Learnability) A _hypothesis class_ $\mathcal{H}$ is agnostic PAC learnable if there exists a function $m_{\mathcal{H}}: (0, 1)^2 \to \mathcal{N}$ and a learning algorithm with the following property: For **every** $\epsilon, \delta \in (0,1)$ and for **every** distribution $\mathcal{D}$ over $X\times Y$, when running the learning algorithm on $m \ge m_{\mathcal{H}}(\epsilon, \delta)$ i.i.d. examples generated by $\mathcal{D}$, the algorithm returns a hypothesis $h$ s.t. with probability of at least $1-\delta$ (over the choice of $m$ training examples),

$$
L_{\mathcal{D}} (h) \le \min_{h^* \in \mathcal{H}} L_{\mathcal{D}}(h^* ) + \epsilon
$$


Agnostic PAC defines the _relative_ distance from the best classifier in the chosen hypothesis class rather then the absolute minimal error.

**Problems beyond binary classification**

- Multiclass classification: the _label set_ is no longer binary, but a finite size set (ex. text classification)
- Regression: the _label set_ is renamed to the _target set_ , and can obtain any value from the set of real numbers.

To accomodate these extensions which mainly only reformulate the loss functio, we introduce _generalized loss functions_.

**Generalized loss functions**

Given any set $\mathcal{H}$ and a domain set $\mathcal{Z}$, we define the _loss function_ $l$ as any function mapping from $HxZ$ to nonnegative real numbers: $l: \mathcal{H}\times \mathbb{Z}\to \mathbb{R}_ +$.

Further, we define a _risk function_ as the expected loss of a classifier $h\in \mathcal{H}$ w.r.t a probability distribution $\mathcal{D}$ over $\mathbb{Z}$:

$$
L_{\mathcal{D}} (h) \stackrel{def}{=} \underset{z\sim \mathcal{D}}{\mathbb{E}} [l (h, z)]
$$

Similarly, the _empirical risk_ is defined as the expected loss over a concrete sample $S = (z_1, \ldots, z_m) \in Z^m$:

$$
L_S(h) \stackrel{def}{=} \frac{1}{m} \sum_{i=1}^m l(h, z_i)
$$

**Agnostic PAC learnability for general loss functions**

**DEFINITION 3.4** (Agnostic PAC for GLF) Everything remains the same as in **3.3** except the loss definition is redefined as: $L_{\mathcal{D}}(h) = \underset{z\sim \mathcal{D}}{\mathbb{E}}[l(h, z)]$

### Chapter 4: Learning via uniform convergence

Idea: we hope that the minimizer of empirical risk is close to the minimizer of the true risk.

Rephrased: we need that uniformly (equally probable for all, none are favored) over all hypotheses in the hypothesis class, the empirical risk will be close to the true risk:

**DEFINITION 4.1.** ($\epsilon$-representative sample) A training set $S$ is called $\epsilon$-representative (w.r.t. domain $\mathbb{Z}$, hypothesis class $\mathcal{H}$ loss function $l$ and distribution $\mathcal{D}$) if:

\begin{equation}
\forall h \in \mathcal{H}, \quad |L_S(h) - L_\mathcal{D}(h)| \le \epsilon
\label{eq:erepr}
\end{equation}

Whenever a training sample (set) is ($\epsilon/2$-representative), the ERM learning rule is guaranteed to return a _good_ hypothesis. 

**LEMMA 4.2.** Assume that a training set $S$ is $\frac{\epsilon}{2}$-representative. Then, any ERM on $S$ satisfies:

$$
L_{\mathcal{D}} (h_S) \le \min_{h\in \mathcal{H}} L_D(h) + \epsilon
$$

**Note**: The formula (\ref{eq:erepr}) contains the absolute value of the difference, meaning that in the text of the proof (omitted here) in steps 1. and 3., the _worst case_ of the inequality is used (as we are computing the _upper bound_).

The requirement for the ERM rule to be an agnostic PAC learner is that with probability of at least $1 - \delta$ we wil sample an $\epsilon$-representative training set.

**DEFINITION 4.3.** (Uniform Convergence) Formalizes the requirement that for a sample size larger than the (UC) sample complexity, we _will_ i.i.d. sample an $\epsilon$-representative sample with probability at least $1-\delta$.

#### Finite hypothesis classes are agnostic PAC learnable

In order to establish that finite hypothesis classes are agnostic PAC learnable, we only need to show that uniform convergence holds in their case.


We start with the inequality similar to section 2, with the realizability assumption replaced by the _generalization gap_.

$$
\mathcal{D}^m (\{ S : \exists h \in \mathcal{H}, \underbrace{|L_S(h) - L_{\mathcal{D}}(h)|}_ {\text{generalization gap}} > \epsilon \}) < \delta
$$

the RHS argument can be rewritten as a union and then a summation through the union bound akin to the steps in section 2. We thus obtain a familiar equation:

$$
\mathcal{D}^m (\{ S : \exists h \in \mathcal{H}, |L_S(h) - L_{\mathcal{D}}(h)| > \epsilon \}) \le \sum_{h \in \mathcal{H}} \mathcal{D}^m (\{ S : |L_S(h) - L_{\mathcal{D}}(h)| > \epsilon\})
$$

The next step is to show that the generalization gap for each fixed hypothesis $h \in \mathcal{H}$ in the RHS is _small enough_, or _likely to be small_. The issue we are dealing with is the difference between the expectation and empirical mean. ($L_{\mathcal{D}}(h) = \mathbb{E}_ {z\sim \mathcal{D}} [l(h, z)]$ and $L_S(h) = \frac{1}{m} \sum_{i=1}^m l(h, z_i)$)

The expected value of $l(h, z_i)$ is actually $L_{\mathcal{D}}(h)$. So, in bounding the difference between the expectation and empirical mean, we are interested in how much do the empirical losses _deviate_ from the expectation, or in other words, we need to show that the measure $L_S(h)$ is _concentrated_ arond the expected value. The law of large numbers says that when $m$ goes to infinity, this gap becomes zero, but does not provide any ensurance on gap width.


**LEMMA 4.5** (Hoeffding's Inequality) Let $\sigma_1, \ldots, \sigma_m$ be a sequence of i.i.d. r.v.'s and assume that for all $i$, $\mathbb{E} [\sigma_i] = \mu$ and $\mathbb{P}[a \le \sigma_i \le b] = 1$. THen, for any $\epsilon > 0$

\begin{equation}
\mathbb{P} \Bigg[ \Bigg| \frac{1}{m} \sum_{i=1}^m \sigma_i - \mu \Bigg| > \epsilon \Bigg] \le 2 \exp(-2\epsilon ^2 / (b - a)^2)
\label{eq:hoeff}
\end{equation}

In our case, $\sigma_i$ is the r.v. $l(h, z_i)$, and $L_{\mathcal{D}}(h) = \mu$. **We assume** the range of $l$ is $[0,1]$, meaning $\sigma_i \in [0,1]$. Plugging this into (\ref{eq:hoeff}), we obtain:

\begin{equation*}
\begin{aligned}
\mathcal{D}^m (\{ S : \exists h \in \mathcal{H}, |L_S(h) - L_{\mathcal{D}}(h)| > \epsilon \}) &\le  \sum_{h \in \mathcal{H}} 2 \exp ( - 2 m \epsilon^2) \\
                                                                                              &= 2 \, |\mathcal{H}| \exp ( - 2 m \epsilon^2)
\end{aligned}
\end{equation*}

If we choose $m$ such that

$$
m \ge \frac{\log (2 \, |\mathcal{H}| / \delta)}{2 \epsilon ^2}
$$

then

$$
\mathcal{D}^m (\{ S : \exists h \in \mathcal{H}, |L_S(h) - L_{\mathcal{D}}(h)| > \epsilon \}) \le \delta.
$$

**COROLLARY 4.6** Let $\mathcal{H}$ be a finite hypothesis class, $Z$ be a domain and $l : \mathcal{H} \times Z \to [0,1]$ be a loss function. Then, $\mathcal{H}$ enjoys the uniform convergence property with sample complexity

$$
m_{\mathcal{H}}^{UC} (\epsilon, \delta) \le \Bigg\lceil \frac{\log (2 |\mathcal{H}| / \delta)}{2\epsilon ^2} \Bigg\rceil.
$$

Furthermore, the class is agnosticaly PAC learnable using the ERM algorithm with sample complexity

$$
m_{\mathcal{H}}(\epsilon, \delta) \le m_{\mathcal{H}}^{UC} (\epsilon/2, \delta) \le \Bigg\lceil \frac{2 \log (2 |\mathcal{H}| / \delta)}{\epsilon ^2} \Bigg\rceil.
$$

_REMARK 4.1_ (The "Discretization Trick"): Most hypothesis classes are infinite (essentially, any hypothesis that uses a real-valued weight), however if we approximate them with machine precision, they become finite due to the limitation of representing floating point numbers.

